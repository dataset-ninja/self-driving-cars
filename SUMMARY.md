**Semantic Segmentation for Self Driving Cars** is a dataset for a semantic segmentation task. Possible applications of the dataset could be in the automotive industry. 

The dataset consists of 5000 images with 344334 labeled objects belonging to 13 different classes including *sky*, *road*, *tree*, and other: *sidewalk*, *car*, *pole*, *road markings*, *building*, *street infrastructure*, *fence*, *wall*, *traffic*, and *pedestrian*.

Images in the Self Driving Cars dataset have pixel-level semantic segmentation annotations. All images are labeled (i.e. with annotations). There are 5 splits in the dataset: *dataA* (1000 images), *dataB* (1000 images), *dataE* (1000 images), *dataD* (1000 images), and *dataC* (1000 images). The dataset was released in 2018.

Here is the visualized example grid with animated annotations:

[animated grid](https://github.com/dataset-ninja/self-driving-cars/raw/main/visualizations/horizontal_grid.webm)
